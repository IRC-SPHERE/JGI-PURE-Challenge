{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(tf_idf, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(tf_idf):\n",
    "        #print(topic.shape)\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nw = len(\\'Abstract\\')\\npids = filtered.loc[filtered.ABSTRACT==\\' \\'].index\\nfor p in pids:\\n    t = filtered.loc[p,\\'TITLE\\']\\n    print (t)\\n    cmd = \"python /home/yu/gits/scholar/scholar.py -c 1 -t --phrase \\'\"+t+\"\\'\"+\" --csv\"\\n    print (cmd)\\n    result = subprocess.check_output(cmd, shell=True)\\n    print (result)\\n    filtered.loc[p,\\'ABSTRACT\\'] = result.split(\\'|\\')[-1][w:]\\n    break\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "w = len('Abstract')\n",
    "pids = filtered.loc[filtered.ABSTRACT==' '].index\n",
    "for p in pids:\n",
    "    t = filtered.loc[p,'TITLE']\n",
    "    print (t)\n",
    "    cmd = \"python /home/yu/gits/scholar/scholar.py -c 1 -t --phrase '\"+t+\"'\"+\" --csv\"\n",
    "    print (cmd)\n",
    "    result = subprocess.check_output(cmd, shell=True)\n",
    "    print (result)\n",
    "    filtered.loc[p,'ABSTRACT'] = result.split('|')[-1][w:]\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = pd.read_csv('filtered_outputs.csv')\n",
    "people = pd.read_csv('people_orgs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "publications['topic'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y2008</th>\n",
       "      <th>y2009</th>\n",
       "      <th>y2010</th>\n",
       "      <th>y2011</th>\n",
       "      <th>y2012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [y2008, y2009, y2010, y2011, y2012]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_years = pd.DataFrame(columns=['y'+str(y) for y in range(2008,2014)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.7, min_df=2,\n",
    "                                max_features=10000,\n",
    "                                stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 50\n",
    "lda = LatentDirichletAllocation(n_topics=T, max_iter=30,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0,\n",
    "                                n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n"
     ]
    }
   ],
   "source": [
    "for year in range(2008,2014):\n",
    "    print(year)\n",
    "    filtered = publications.loc[publications.PUBLICATION_YEAR==year]\n",
    "    docs = map(lambda i: filtered.TITLE[i]+filtered.ABSTRACT[i], filtered.index)\n",
    "    \n",
    "    doc_word_mtrx = tf_vectorizer.fit_transform(docs)\n",
    "    for w in tf_vectorizer.vocabulary_.keys():\n",
    "        if len(w) < 3 or any(x.isdigit() for x in w):\n",
    "            del tf_vectorizer.vocabulary_[w]\n",
    "    doc_word_mtrx = tf_vectorizer.transform(docs)\n",
    "    \n",
    "    df = reduce(lambda x,y:x+y, doc_word_mtrx)\n",
    "    df = df.toarray()\n",
    "    df[df==0]=np.max(df)\n",
    "    \n",
    "    doc_topic=lda.fit_transform(doc_word_mtrx)\n",
    "    dp = np.argsort(doc_topic,1)[:,-1]\n",
    "    tp_doc_counts=np.zeros(T)\n",
    "    for t in range(T):\n",
    "        tp_doc_counts[t] = (dp==t).sum()\n",
    "        \n",
    "    trank = tp_doc_counts.argsort()\n",
    "    n_top_words = 50\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    for t in range(T):\n",
    "        topic_years.loc[t,'y'+str(year)] = \",\".join(tf_feature_names[k] for k in lda.components_[trank[-t-1]].argsort()[:-n_top_words - 1:-1])\n",
    "        publications.loc[filtered.index[dp==trank[-t-1]],'topic'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_years.to_csv('topic_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.PERSON_ID.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_topic = pd.merge(publications, people, on='PUBLICATION_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_size = pd.DataFrame()\n",
    "for year in range(2008,2014):\n",
    "    #topic_orgs[year] = {}\n",
    "    ycol = 'y'+str(year)\n",
    "    for t in range(T):\n",
    "        topic_size.loc[t,ycol+'_num_people'] = people_topic.loc[(people_topic.PUBLICATION_YEAR==year)&(people_topic.topic==t)].PERSON_ID.unique().shape[0]\n",
    "        topic_size.loc[t,ycol+'_num_orgs'] = people_topic.loc[(people_topic.PUBLICATION_YEAR==year)&(people_topic.topic==t)].ORGANISATION_CODE.unique().shape[0]\n",
    "        topic_size.loc[t,ycol+'_num_docs'] = people_topic.loc[(people_topic.PUBLICATION_YEAR==year)&(people_topic.topic==t)].PUBLICATION_ID.unique().shape[0]\n",
    "        #topic_orgs[year][t]={'num_people':num_people,'num_orgs':num_orgs,'num_docs':num_docs}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_size.to_csv('topic_size.csv',index=False,float_format='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_orgs = pd.DataFrame()\n",
    "orgs = people_topic.ORGANISATION_CODE.unique()\n",
    "N = len(orgs)\n",
    "count = np.zeros(N)\n",
    "for year in range(2008,2014):    \n",
    "    ycol = 'y'+str(year)\n",
    "    f = people_topic.loc[(people_topic.PUBLICATION_YEAR==year)]\n",
    "    for t in range(T):\n",
    "        ff = f.loc[(f.topic==t)]\n",
    "        count*=0\n",
    "        for n,o in enumerate(orgs):\n",
    "            count[n] = ff.loc[(ff.ORGANISATION_CODE==o)].PUBLICATION_ID.unique().shape[0]\n",
    "        topic_orgs.loc[t,ycol] = ','.join(org for org in orgs[count.argsort()[-5:]])+' ('+','.join(str(int(c)) for c in np.sort(count)[-5:])+')'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y2008</th>\n",
       "      <th>y2009</th>\n",
       "      <th>y2010</th>\n",
       "      <th>y2011</th>\n",
       "      <th>y2012</th>\n",
       "      <th>y2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPOL,QUEN,MVEN,SOCS,SSCM (106,138,144,154,406)</td>\n",
       "      <td>GELY,CHEM,PHYS,MVEN,QUEN (98,152,171,318,387)</td>\n",
       "      <td>SPAI,LAWD,EDUC,SOCS,SSCM (98,103,112,124,250)</td>\n",
       "      <td>GELY,CHEM,PHYS,MVEN,QUEN (126,127,153,274,305)</td>\n",
       "      <td>VESC,EDUC,SPOL,SOCS,SSCM (88,90,110,158,395)</td>\n",
       "      <td>GEOG,PHYS,MATH,MVEN,QUEN (76,88,120,292,427)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MVEN,GELY,PHYS,QUEN,CHEM (60,111,116,146,176)</td>\n",
       "      <td>BISC,PSYC,VESC,SOCS,SSCM (44,65,84,190,294)</td>\n",
       "      <td>GELY,CHEM,PHYS,MVEN,QUEN (49,100,126,217,329)</td>\n",
       "      <td>SPAI,GEOG,SSCM,HUMS,EDUC (72,81,85,92,107)</td>\n",
       "      <td>GELY,MVEN,CHEM,PHYS,QUEN (91,119,133,166,347)</td>\n",
       "      <td>SART,LAWD,SPAI,GEOG,HUMS (67,70,93,94,109)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SSCM,PANM,BIOC,PHPH,SOCS (27,36,54,82,143)</td>\n",
       "      <td>SSCM,LAWD,SPAI,SPOL,EDUC (38,45,48,58,114)</td>\n",
       "      <td>MATH,GEOG,SOCS,MVEN,SSCM (75,78,79,96,140)</td>\n",
       "      <td>VESC,PSYC,SPOL,SOCS,SSCM (59,61,85,179,408)</td>\n",
       "      <td>BISC,PHYS,MATH,QUEN,MVEN (32,34,68,78,191)</td>\n",
       "      <td>QUEN,GEOG,GELY,PHYS,CHEM (47,115,138,147,177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HUMS,PHYS,MATH,MVEN,QUEN (31,38,49,64,86)</td>\n",
       "      <td>CHEM,PANM,PHPH,BIOC,SOCS (25,44,80,80,105)</td>\n",
       "      <td>BISC,PANM,BIOC,PHPH,SOCS (30,69,71,91,147)</td>\n",
       "      <td>BIOC,SSCM,PHPH,VESC,SOCS (54,69,82,90,225)</td>\n",
       "      <td>VESC,PANM,PHPH,BIOC,SOCS (42,62,73,90,196)</td>\n",
       "      <td>VESC,EDUC,SPOL,SOCS,SSCM (43,44,55,157,285)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPAI,LAWD,MODL,EDUC,HUMS (27,28,30,60,65)</td>\n",
       "      <td>BISC,ORDS,VESC,SOCS,SSCM (22,22,53,54,111)</td>\n",
       "      <td>PHPH,SSCM,SOCS,VESC,CHEM (8,11,31,46,63)</td>\n",
       "      <td>BIOC,VICH,DPPP,PHYS,CHEM (7,8,11,53,110)</td>\n",
       "      <td>QUEN,BISC,GEOG,CHEM,GELY (20,21,86,92,123)</td>\n",
       "      <td>SPOL,PSYC,VESC,SOCS,SSCM (34,39,60,148,341)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            y2008  \\\n",
       "0  SPOL,QUEN,MVEN,SOCS,SSCM (106,138,144,154,406)   \n",
       "1   MVEN,GELY,PHYS,QUEN,CHEM (60,111,116,146,176)   \n",
       "2      SSCM,PANM,BIOC,PHPH,SOCS (27,36,54,82,143)   \n",
       "3       HUMS,PHYS,MATH,MVEN,QUEN (31,38,49,64,86)   \n",
       "4       SPAI,LAWD,MODL,EDUC,HUMS (27,28,30,60,65)   \n",
       "\n",
       "                                           y2009  \\\n",
       "0  GELY,CHEM,PHYS,MVEN,QUEN (98,152,171,318,387)   \n",
       "1    BISC,PSYC,VESC,SOCS,SSCM (44,65,84,190,294)   \n",
       "2     SSCM,LAWD,SPAI,SPOL,EDUC (38,45,48,58,114)   \n",
       "3     CHEM,PANM,PHPH,BIOC,SOCS (25,44,80,80,105)   \n",
       "4     BISC,ORDS,VESC,SOCS,SSCM (22,22,53,54,111)   \n",
       "\n",
       "                                           y2010  \\\n",
       "0  SPAI,LAWD,EDUC,SOCS,SSCM (98,103,112,124,250)   \n",
       "1  GELY,CHEM,PHYS,MVEN,QUEN (49,100,126,217,329)   \n",
       "2     MATH,GEOG,SOCS,MVEN,SSCM (75,78,79,96,140)   \n",
       "3     BISC,PANM,BIOC,PHPH,SOCS (30,69,71,91,147)   \n",
       "4       PHPH,SSCM,SOCS,VESC,CHEM (8,11,31,46,63)   \n",
       "\n",
       "                                            y2011  \\\n",
       "0  GELY,CHEM,PHYS,MVEN,QUEN (126,127,153,274,305)   \n",
       "1      SPAI,GEOG,SSCM,HUMS,EDUC (72,81,85,92,107)   \n",
       "2     VESC,PSYC,SPOL,SOCS,SSCM (59,61,85,179,408)   \n",
       "3      BIOC,SSCM,PHPH,VESC,SOCS (54,69,82,90,225)   \n",
       "4        BIOC,VICH,DPPP,PHYS,CHEM (7,8,11,53,110)   \n",
       "\n",
       "                                           y2012  \\\n",
       "0   VESC,EDUC,SPOL,SOCS,SSCM (88,90,110,158,395)   \n",
       "1  GELY,MVEN,CHEM,PHYS,QUEN (91,119,133,166,347)   \n",
       "2     BISC,PHYS,MATH,QUEN,MVEN (32,34,68,78,191)   \n",
       "3     VESC,PANM,PHPH,BIOC,SOCS (42,62,73,90,196)   \n",
       "4     QUEN,BISC,GEOG,CHEM,GELY (20,21,86,92,123)   \n",
       "\n",
       "                                           y2013  \n",
       "0   GEOG,PHYS,MATH,MVEN,QUEN (76,88,120,292,427)  \n",
       "1     SART,LAWD,SPAI,GEOG,HUMS (67,70,93,94,109)  \n",
       "2  QUEN,GEOG,GELY,PHYS,CHEM (47,115,138,147,177)  \n",
       "3    VESC,EDUC,SPOL,SOCS,SSCM (43,44,55,157,285)  \n",
       "4    SPOL,PSYC,VESC,SOCS,SSCM (34,39,60,148,341)  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_orgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_orgs.to_csv('topic_orgs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
